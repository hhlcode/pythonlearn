{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 朴素贝叶斯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入包\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "#导入数据集\n",
    "from sklearn import datasets\n",
    "iris=datasets.load_iris()#鸢尾花数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntrain_X,test_X,train_y,test_y = train_test_split(train_data,train_target,test_size=0.3,random_state=5)\\n\\n参数解释：\\n\\ntrain_data：待划分样本数据\\n\\ntrain_target：待划分样本数据的结果（标签）\\n\\ntest_size：测试数据占样本数据的比例，若整数则样本数量\\n\\nrandom_state：设置随机数种子，保证每次都是同一个随机数。若为0或不填，则每次得到数据都不一样\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#切分数据集\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(iris.data,\n",
    "iris.target,\n",
    "random_state=12)\n",
    "\"\"\"\n",
    "train_X,test_X,train_y,test_y = train_test_split(train_data,train_target,test_size=0.3,random_state=5)\n",
    "\n",
    "参数解释：\n",
    "\n",
    "train_data：待划分样本数据\n",
    "\n",
    "train_target：待划分样本数据的结果（标签）\n",
    "\n",
    "test_size：测试数据占样本数据的比例，若整数则样本数量\n",
    "\n",
    "random_state：设置随机数种子，保证每次都是同一个随机数。若为0或不填，则每次得到数据都不一样\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#建模\n",
    "clf = GaussianNB()#高斯贝叶斯分布\n",
    "clf.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 0, 1, 2, 2, 2, 0, 2, 0, 1, 0, 0, 0, 1, 2, 2, 1, 0, 1, 0, 1,\n",
       "       2, 1, 0, 2, 2, 1, 0, 0, 0, 1, 2, 0, 2, 0, 1, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#在测试集上执行预测,proba导出的是每个样本属于某类的概率\n",
    "clf.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e+000, 2.32926069e-017, 1.81656357e-023],\n",
       "       [4.28952299e-154, 2.48576754e-002, 9.75142325e-001],\n",
       "       [1.00000000e+000, 7.45528845e-018, 3.79800436e-024],\n",
       "       [3.59748710e-076, 9.99751806e-001, 2.48194200e-004],\n",
       "       [2.20411871e-239, 4.45798016e-009, 9.99999996e-001],\n",
       "       [1.23795145e-173, 1.95814902e-003, 9.98041851e-001],\n",
       "       [2.45866589e-206, 2.34481513e-007, 9.99999766e-001],\n",
       "       [1.00000000e+000, 2.61810906e-017, 2.67446831e-023],\n",
       "       [3.07448595e-259, 9.07196639e-011, 1.00000000e+000],\n",
       "       [1.00000000e+000, 1.14549667e-010, 3.00314173e-017],\n",
       "       [1.64566141e-101, 9.87428016e-001, 1.25719837e-002],\n",
       "       [1.00000000e+000, 5.62770009e-016, 8.77233124e-022],\n",
       "       [1.00000000e+000, 9.78098062e-014, 4.81247272e-020],\n",
       "       [1.00000000e+000, 3.96616431e-015, 3.17162008e-021],\n",
       "       [2.58159395e-110, 7.85918892e-001, 2.14081108e-001],\n",
       "       [8.01004975e-208, 8.36611920e-006, 9.99991634e-001],\n",
       "       [2.27845999e-193, 5.52863568e-004, 9.99447136e-001],\n",
       "       [2.52133012e-090, 9.94597495e-001, 5.40250471e-003],\n",
       "       [1.00000000e+000, 4.06675976e-017, 2.53312064e-023],\n",
       "       [3.29537129e-123, 9.22312452e-001, 7.76875484e-002],\n",
       "       [1.00000000e+000, 4.66765440e-017, 1.99662820e-023],\n",
       "       [7.54708431e-074, 9.99690656e-001, 3.09343577e-004],\n",
       "       [6.27117035e-136, 1.83265786e-001, 8.16734214e-001],\n",
       "       [4.68960290e-103, 9.82756006e-001, 1.72439943e-002],\n",
       "       [1.00000000e+000, 2.15636250e-014, 2.25086772e-020],\n",
       "       [5.92924136e-199, 5.41122729e-007, 9.99999459e-001],\n",
       "       [4.07679795e-141, 7.38689632e-002, 9.26131037e-001],\n",
       "       [2.77929930e-083, 9.99806458e-001, 1.93541791e-004],\n",
       "       [1.00000000e+000, 4.48465501e-017, 4.36464333e-023],\n",
       "       [1.00000000e+000, 1.64440161e-014, 1.13341951e-021],\n",
       "       [1.00000000e+000, 8.68192867e-017, 6.71630735e-023],\n",
       "       [7.15007036e-050, 9.99997055e-001, 2.94492877e-006],\n",
       "       [1.73414331e-178, 2.06441448e-003, 9.97935586e-001],\n",
       "       [1.00000000e+000, 4.90168069e-019, 3.86471595e-024],\n",
       "       [1.35600871e-156, 2.28929843e-002, 9.77107016e-001],\n",
       "       [1.00000000e+000, 1.78544881e-015, 1.09390819e-020],\n",
       "       [1.86074590e-058, 9.99948860e-001, 5.11400371e-005],\n",
       "       [3.69548269e-057, 9.99992986e-001, 7.01435008e-006]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9736842105263158"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#测试准确率\n",
    "accuracy_score(ytest, clf.predict(Xtest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 朴素贝叶斯之鸢尾花数据实验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3            4\n",
       "0  5.1  3.5  1.4  0.2  Iris-setosa\n",
       "1  4.9  3.0  1.4  0.2  Iris-setosa\n",
       "2  4.7  3.2  1.3  0.2  Iris-setosa\n",
       "3  4.6  3.1  1.5  0.2  Iris-setosa\n",
       "4  5.0  3.6  1.4  0.2  Iris-setosa"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "dataSet =pd.read_csv('iris.txt',header = None)\n",
    "dataSet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\"\"\"\n",
    "函数功能:随机切分训练集和测试集\n",
    "参数说明:\n",
    "dataSet:输入的数据集\n",
    "rate:训练集所占比例\n",
    "返回:切分好的训练集和测试集\n",
    "\"\"\"\n",
    "def randSplit(dataSet, rate):\n",
    "    l = list(dataSet.index) #提取出索引\n",
    "    random.shuffle(l) #随机打乱索引\n",
    "#     print(l)\n",
    "    dataSet.index = l #将打乱后的索引重新赋值给原数据集\n",
    "    n = dataSet.shape[0] #总行数\n",
    "    m = int(n * rate) #训练集的数量\n",
    "    train = dataSet.loc[range(m), :] #提取前m个记录作为训练集\n",
    "    test = dataSet.loc[range(m, n), :] #剩下的作为测试集\n",
    "    dataSet.index = range(dataSet.shape[0]) #更新原数据集的索引\n",
    "    test.index = range(test.shape[0])\n",
    "    #更新测试集的索引\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test= randSplit(dataSet, 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构建高斯朴素贝叶斯分类器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gnb_classify(train,test):\n",
    "    labels = train.iloc[:,-1].value_counts().index #提取训练集的标签种类\n",
    "    mean =[] #存放每个类别的均值\n",
    "    std =[] #存放每个类别的方差\n",
    "    result = [] #存放测试集的预测结果\n",
    "    for i in labels:\n",
    "        item = train.loc[train.iloc[:,-1]==i,:] #分别提取出每一种类别\n",
    "        m = item.iloc[:,:-1].mean() #当前类别的平均值\n",
    "        s = np.sum((item.iloc[:,:-1]-m)**2)/(item.shape[0]) #当前类别的方差\n",
    "        mean.append(m) #将当前类别的平均值追加至列表\n",
    "        std.append(s) #将当前类别的方差追加至列表\n",
    "    means = pd.DataFrame(mean,index=labels) #变成DF格式,索引为类标签\n",
    "    stds = pd.DataFrame(std,index=labels) #变成DF格式,索引为类标签\n",
    "    for j in range(test.shape[0]):\n",
    "        iset = test.iloc[j,:-1].tolist()\n",
    "        #当前测试实例\n",
    "        iprob = np.exp(-1*(iset-means)**2/(stds*2))/(np.sqrt(2*np.pi*stds)) #正态分布公式\n",
    "        prob = 1 #初始化当前实例总概率\n",
    "        for k in range(test.shape[1]-1): #遍历每个特征\n",
    "            prob *= iprob[k] #特征概率之积即为当前实例概率\n",
    "            cla = prob.index[np.argmax(prob.values)] #返回最大概率的类别\n",
    "        result.append(cla)\n",
    "    test['predict']=result\n",
    "    acc = (test.iloc[:,-1]==test.iloc[:,-2]).mean()\n",
    "    #计算预测准确率\n",
    "    print(f'模型预测准确率为{acc}')\n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型预测准确率为0.9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.6</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.1</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.1</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6.2</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>2.2</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.1</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7.3</td>\n",
       "      <td>2.9</td>\n",
       "      <td>6.3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5.2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.4</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.2</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>7.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.2</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1    2    3                4          predict\n",
       "0   5.0  3.5  1.3  0.3      Iris-setosa      Iris-setosa\n",
       "1   5.6  2.5  3.9  1.1  Iris-versicolor  Iris-versicolor\n",
       "2   5.1  3.8  1.6  0.2      Iris-setosa      Iris-setosa\n",
       "3   4.6  3.2  1.4  0.2      Iris-setosa      Iris-setosa\n",
       "4   5.6  3.0  4.1  1.3  Iris-versicolor  Iris-versicolor\n",
       "5   5.1  3.5  1.4  0.2      Iris-setosa      Iris-setosa\n",
       "6   6.7  3.1  4.4  1.4  Iris-versicolor  Iris-versicolor\n",
       "7   5.9  3.2  4.8  1.8  Iris-versicolor   Iris-virginica\n",
       "8   6.9  3.1  5.4  2.1   Iris-virginica   Iris-virginica\n",
       "9   6.2  2.9  4.3  1.3  Iris-versicolor  Iris-versicolor\n",
       "10  6.5  3.0  5.8  2.2   Iris-virginica   Iris-virginica\n",
       "11  5.6  3.0  4.5  1.5  Iris-versicolor  Iris-versicolor\n",
       "12  6.7  3.3  5.7  2.1   Iris-virginica   Iris-virginica\n",
       "13  7.3  2.9  6.3  1.8   Iris-virginica   Iris-virginica\n",
       "14  6.1  2.6  5.6  1.4   Iris-virginica  Iris-versicolor\n",
       "15  4.4  3.0  1.3  0.2      Iris-setosa      Iris-setosa\n",
       "16  4.8  3.1  1.6  0.2      Iris-setosa      Iris-setosa\n",
       "17  6.3  3.3  6.0  2.5   Iris-virginica   Iris-virginica\n",
       "18  5.2  3.5  1.5  0.2      Iris-setosa      Iris-setosa\n",
       "19  5.8  2.8  5.1  2.4   Iris-virginica   Iris-virginica\n",
       "20  5.8  2.7  3.9  1.2  Iris-versicolor  Iris-versicolor\n",
       "21  5.8  2.7  4.1  1.0  Iris-versicolor  Iris-versicolor\n",
       "22  6.1  2.9  4.7  1.4  Iris-versicolor  Iris-versicolor\n",
       "23  7.7  2.8  6.7  2.0   Iris-virginica   Iris-virginica\n",
       "24  4.8  3.0  1.4  0.1      Iris-setosa      Iris-setosa\n",
       "25  4.8  3.4  1.9  0.2      Iris-setosa      Iris-setosa\n",
       "26  5.4  3.0  4.5  1.5  Iris-versicolor  Iris-versicolor\n",
       "27  6.9  3.1  4.9  1.5  Iris-versicolor   Iris-virginica\n",
       "28  7.7  3.8  6.7  2.2   Iris-virginica   Iris-virginica\n",
       "29  4.9  3.1  1.5  0.1      Iris-setosa      Iris-setosa"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb_classify(train,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型预测准确率为0.9666666666666667\n",
      "模型预测准确率为0.9666666666666667\n",
      "模型预测准确率为0.8666666666666667\n",
      "模型预测准确率为0.9666666666666667\n",
      "模型预测准确率为0.9666666666666667\n",
      "模型预测准确率为0.9333333333333333\n",
      "模型预测准确率为0.9333333333333333\n",
      "模型预测准确率为0.9666666666666667\n",
      "模型预测准确率为0.9\n",
      "模型预测准确率为0.9666666666666667\n",
      "模型预测准确率为0.9666666666666667\n",
      "模型预测准确率为0.9666666666666667\n",
      "模型预测准确率为0.9333333333333333\n",
      "模型预测准确率为0.9666666666666667\n",
      "模型预测准确率为0.9666666666666667\n",
      "模型预测准确率为1.0\n",
      "模型预测准确率为1.0\n",
      "模型预测准确率为1.0\n",
      "模型预测准确率为1.0\n",
      "模型预测准确率为0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    train,test= randSplit(dataSet, 0.8)\n",
    "    gnb_classify(train,test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用朴素贝叶斯进行文档分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "函数功能:创建实验数据集\n",
    "参数说明:无参数\n",
    "返回:\n",
    "postingList:切分好的样本词条\n",
    "classVec:类标签向量\n",
    "\"\"\"\n",
    "def loadDataSet():\n",
    "    dataSet=[['my', 'dog', 'has', 'flea', 'problems', 'help', 'please'],\n",
    "    ['maybe', 'not', 'take', 'him', 'to', 'dog', 'park', 'stupid'],\n",
    "    ['my', 'dalmation', 'is', 'so', 'cute', 'I', 'love', 'him'],\n",
    "    ['stop', 'posting', 'stupid', 'worthless', 'garbage'],\n",
    "    ['mr', 'licks', 'ate', 'my', 'steak', 'how', 'to', 'stop', 'him'],\n",
    "    ['quit', 'buying', 'worthless', 'dog', 'food', 'stupid']] #切分好的词条\n",
    "    classVec = [0,1,0,1,0,1]\n",
    "    #类别标签向量,1代表侮辱性词汇,0代表非侮辱性词汇\n",
    "    return dataSet,classVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSet,classVec=loadDataSet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "函数功能:将切分的样本词条整理成词汇表(不重复)\n",
    "参数说明:\n",
    "dataSet:切分好的样本词条\n",
    "返回:\n",
    "vocabList:不重复的词汇表\n",
    "\"\"\"\n",
    "def createVocabList(dataSet):\n",
    "    vocabSet = set() #创建一个空的集合\n",
    "    for doc in dataSet: #遍历dataSet中的每一条言论\n",
    "        vocabSet = vocabSet | set(doc)#取并集\n",
    "    vocabList = list(vocabSet)\n",
    "    return vocabList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['food', 'garbage', 'worthless', 'please', 'him', 'love', 'I', 'help', 'licks', 'cute', 'buying', 'park', 'is', 'stop', 'so', 'flea', 'steak', 'maybe', 'posting', 'has', 'how', 'mr', 'my', 'take', 'dog', 'to', 'not', 'problems', 'ate', 'quit', 'stupid', 'dalmation']\n"
     ]
    }
   ],
   "source": [
    "vocabList = createVocabList(dataSet)\n",
    "print(vocabList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"函数功能:根据vocabList词汇表,将inputSet向量化,向量的每个元素为1或0\n",
    "参数说明:\n",
    "vocabList:词汇表\n",
    "inputSet:切分好的词条列表中的一条\n",
    "返回:\n",
    "returnVec:文档向量,词集模型\n",
    "\"\"\"\n",
    "def setOfWords2Vec(vocabList, inputSet):\n",
    "    returnVec = [0] * len(vocabList) #创建一个其中所含元素都为0的向量\n",
    "    for word in inputSet: #遍历每个词条\n",
    "        if word in vocabList:\n",
    "        #如果词条存在于词汇表中,则变为1\n",
    "            returnVec[vocabList.index(word)] = 1\n",
    "        else:\n",
    "            print(f\" {word} is not in my Vocabulary!\" )\n",
    "    return returnVec\n",
    "    #返回文档向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "函数功能:生成训练集向量列表\n",
    "参数说明:\n",
    "dataSet:切分好的样本词条\n",
    "返回:\n",
    "trainMat:所有的词条向量组成的列表\n",
    "\"\"\"\n",
    "def get_trainMat(dataSet):\n",
    "    trainMat = [] #初始化向量列表\n",
    "    vocabList = createVocabList(dataSet) #生成词汇表\n",
    "    for inputSet in dataSet:\n",
    "        #遍历样本词条中的每一条样本\n",
    "        returnVec=setOfWords2Vec(vocabList, inputSet) #将当前词条向量化\n",
    "        trainMat.append(returnVec) #追加到向量列表中\n",
    "    return trainMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0], [0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0], [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0]]\n"
     ]
    }
   ],
   "source": [
    "trainMat = get_trainMat(dataSet)\n",
    "print(trainMat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "函数功能:朴素贝叶斯分类器训练函数\n",
    "参数说明:\n",
    "trainMat:训练文档矩阵\n",
    "classVec:训练类别标签向量\n",
    "返回:\n",
    "p0V:非侮辱类的条件概率数组\n",
    "p1V:侮辱类的条件概率数组\n",
    "\"\"\"\n",
    "def trainNB(trainMat,classVec):\n",
    "    n = len(trainMat) #计算训练的文档数目\n",
    "    m = len(trainMat[0]) #计算每篇文档的词条数\n",
    "    pAb = sum(classVec)/n #文档属于侮辱类的概率\n",
    "    p0Num = np.zeros(m) #词条出现数初始化为0\n",
    "    p1Num = np.zeros(m) #词条出现数初始化为0\n",
    "    p0Denom = 0 #分母初始化为0\n",
    "    p1Denom = 0 #分母初始化为0\n",
    "    for i in range(n): #遍历每一个文档\n",
    "        if classVec[i] == 1:\n",
    "            #统计属于侮辱类的条件概率所需的数据\n",
    "            p1Num += trainMat[i]\n",
    "            p1Denom += sum(trainMat[i])\n",
    "        else:\n",
    "            #统计属于非侮辱类的条件概率所需的数据\n",
    "            p0Num += trainMat[i]\n",
    "            p0Denom += sum(trainMat[i])\n",
    "    p1V = p1Num/p1Denom\n",
    "    p0V = p0Num/p0Denom\n",
    "    return p0V,p1V,pAb\n",
    "    #返回属于非侮辱类,侮辱类和文档属于侮辱类的概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "p0V,p1V,pAb = trainNB(trainMat, classVec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 朴素贝叶斯分类器训练函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\"\"\"\n",
    "函数功能:朴素贝叶斯分类器分类函数\n",
    "参数说明:\n",
    "vec2Classify:待分类的词条数组\n",
    "p0V:非侮辱类的条件概率数组\n",
    "p1V:侮辱类的条件概率数组\n",
    "pAb:文档属于侮辱类的概率\n",
    "返回:\n",
    "0:属于非侮辱类\n",
    "1:属于侮辱类\n",
    "\"\"\"\n",
    "def classifyNB(vec2Classify, p0V, p1V, pAb):\n",
    "    p1 = reduce(lambda x,y:x*y, vec2Classify * p1V) * pAb\n",
    "    #对应元素相乘\n",
    "    p0 = reduce(lambda x,y:x*y, vec2Classify * p0V) * (1 - pAb)\n",
    "    print('p0:',p0)\n",
    "    print('p1:',p1)\n",
    "    if p1 > p0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "函数功能:朴素贝叶斯测试函数\n",
    "参数说明:\n",
    "testVec:测试样本\n",
    "返回:测试样本的类别\n",
    "\"\"\"\n",
    "def testingNB(testVec):\n",
    "    dataSet,classVec = loadDataSet() #创建实验样本\n",
    "    vocabList = createVocabList(dataSet) #创建词汇表\n",
    "    trainMat= get_trainMat(dataSet) #将实验样本向量化\n",
    "    p0V,p1V,pAb = trainNB(trainMat,classVec) #训练朴素贝叶斯分类器\n",
    "    thisone = setOfWords2Vec(vocabList, testVec) #测试样本向量化\n",
    "    if classifyNB(thisone,p0V,p1V,pAb):\n",
    "        print(testVec,'属于侮辱类')\n",
    "        #执行分类并打印分类结果\n",
    "    else:\n",
    "        print(testVec,'属于非侮辱类')\n",
    "        #执行分类并打印分类结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p0: 0.0\n",
      "p1: 0.0\n",
      "['love', 'my', 'dalmation'] 属于非侮辱类\n",
      "p0: 0.0\n",
      "p1: 0.0\n",
      "['stupid', 'garbage'] 属于非侮辱类\n"
     ]
    }
   ],
   "source": [
    "    #测试样本1\n",
    "    testVec1 = ['love', 'my', 'dalmation']\n",
    "    testingNB(testVec1)\n",
    "    #测试样本2\n",
    "    testVec2 = ['stupid', 'garbage']\n",
    "    testingNB(testVec2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainNB(trainMat,classVec):\n",
    "    n = len(trainMat) #计算训练的文档数目\n",
    "    m = len(trainMat[0]) #计算每篇文档的词条数\n",
    "    pAb = sum(classVec)/n #文档属于侮辱类的概率\n",
    "    p0Num = np.ones(m) #词条出现数初始化为1\n",
    "    p1Num = np.ones(m) #词条出现数初始化为1\n",
    "    p0Denom = 2 #分母初始化为2\n",
    "    p1Denom = 2 #分母初始化为2\n",
    "    for i in range(n): #遍历每一个文档\n",
    "        if classVec[i] == 1:\n",
    "            #统计属于侮辱类的条件概率所需的数据\n",
    "            p1Num += trainMat[i]\n",
    "            p1Denom += sum(trainMat[i])\n",
    "        else:\n",
    "            #统计属于非侮辱类的条件概率所需的数据\n",
    "            p0Num += trainMat[i]\n",
    "            p0Denom += sum(trainMat[i])\n",
    "    p1V = np.log(p1Num/p1Denom)\n",
    "    p0V = np.log(p0Num/p0Denom)\n",
    "    return p0V,p1V,pAb\n",
    "    #返回属于非侮辱类,侮辱类和文档属于侮辱类的概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "p0V,p1V,pAb = trainNB(trainMat,classVec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifyNB(vec2Classify, p0V, p1V, pAb):\n",
    "    p1 = sum(vec2Classify * p1V) + np.log(pAb) #对应元素相乘\n",
    "    p0 = sum(vec2Classify * p0V) + np.log(1- pAb) #对应元素相乘\n",
    "    if p1 > p0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '测试样本1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-5d4ff6697a88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0m测试样本1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtestVec1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'love'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'my'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dalmation'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtestingNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestVec1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name '测试样本1' is not defined"
     ]
    }
   ],
   "source": [
    "测试样本1\n",
    "testVec1 = ['love', 'my', 'dalmation']\n",
    "testingNB(testVec1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
